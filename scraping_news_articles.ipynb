{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping News Aritcles - Hindi Newspaper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Scraping newspaper article from a newpaper website. A program that will navigate thorught the section of the newspaper and there pages to scrap news articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import time\n",
    "import urllib\n",
    "import requests\n",
    "import bs4\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jagaran Newspaper's official url\n",
    "url = \"https://www.jagran.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to request a link\n",
    "def request_url(link):\n",
    "    \"\"\"\n",
    "    It takes a url and returns the html as string.\n",
    "    \"\"\"\n",
    "    ## Slow things down ## \n",
    "    ## Let the site breath ##\n",
    "    time.sleep(2)\n",
    "    \n",
    "    response = requests.get(link)\n",
    "    html = response.text\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse html\n",
    "def parse_html(to_parse):\n",
    "    \"\"\"\n",
    "    It takes a string, then parse it.\n",
    "    Finally, it retuns a soup object.\n",
    "    \"\"\"\n",
    "    soup = bs4.BeautifulSoup(to_parse, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to collect all sections links\n",
    "# Like world news, national news ...\n",
    "\n",
    "def all_section(main_url):\n",
    "    \"\"\"\n",
    "    It takes a main url of the newspaper and then\n",
    "    finds almost all the sections in the newspaper.\n",
    "    Finally, it returns the section which we will scrap.\n",
    "    \"\"\"\n",
    "    soup = parse_html(request_url(url))\n",
    "    ul = soup.find(\"div\", class_=\"MainLMenu tab\").ul\n",
    "    section_list = []\n",
    "    for li in ul.find_all(\"li\"):\n",
    "        section_list.append(li.a.get('href'))\n",
    "    # Remove the section which we will not consider\n",
    "    # Like the video section and others\n",
    "    remove = [0, 1, -1, -1, -1]\n",
    "    for i in remove:\n",
    "        section_list.remove(section_list[i])\n",
    "    return section_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All section url (half-urls)\n",
    "section_urls = all_section(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/latest-news.html',\n",
       " '/news/national-news-hindi.html',\n",
       " '/feature-news-hindi.html',\n",
       " '/politics-news-hindi.html',\n",
       " '/world-news-hindi.html',\n",
       " '/common-man-issue-news-hindi.html',\n",
       " '/technology-hindi.html',\n",
       " '/business-hindi.html',\n",
       " '/cricket-hindi.html',\n",
       " '/automobile',\n",
       " '/lifestyle-hindi.html']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the sections urls\n",
    "section_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Orientation of the section pages**\n",
    "\n",
    "In this newspaper there are basically two types of layouts: Grid View and List View. So we will filter the section of the grid and list view seperately. As depending upon the layouts the html fromat cahges, therefore we will have to scrap them differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep url of the section which has Grid layout\n",
    "grid_layout_urls = [3, 4, 6, 7, 8, 9]\n",
    "\n",
    "# All Grid half urls\n",
    "grid_urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Keep url of the section, which has linear layout(List) view\n",
    "list_layout_urls = [0, 1, 5]\n",
    "\n",
    "# All List half urls\n",
    "list_urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting only Gride View section page urls\n",
    "for filter_url in grid_layout_urls:\n",
    "    grid_urls.append(section_urls[filter_url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting only List View section page urls\n",
    "for filter_url in list_layout_urls:\n",
    "    list_urls.append(section_urls[filter_url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/politics-news-hindi.html',\n",
       " '/world-news-hindi.html',\n",
       " '/technology-hindi.html',\n",
       " '/business-hindi.html',\n",
       " '/cricket-hindi.html',\n",
       " '/automobile']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the Grid View urls\n",
    "grid_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/latest-news.html',\n",
       " '/news/national-news-hindi.html',\n",
       " '/common-man-issue-news-hindi.html']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking List view urls\n",
    "list_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
